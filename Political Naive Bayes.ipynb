{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ravita Kartawinata\n",
    "[Ravita's Git ](https://github.com/Pii-USD/509-tm-nb-conventions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/users/rkartawi/Desktop/Ravita/MSADS/509/Mod4/2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # query to get the tables and colums name for next query\n",
    "# # Chatgpt\n",
    "# convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# tables = convention_cur.fetchall()\n",
    "\n",
    "# # Get table names and their columns\n",
    "# for table_name in tables:\n",
    "#     table_name = table_name[0] \n",
    "#     print(f\"\\nTable: {table_name}\")\n",
    "    \n",
    "#     convention_cur.execute(f\"PRAGMA table_info({table_name});\")\n",
    "#     schema = convention_cur.fetchall()\n",
    "    \n",
    "#     for column in schema:\n",
    "#         print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "convention_data = []\n",
    "\n",
    "query_results = convention_cur.execute(\"SELECT text, party FROM conventions\")\n",
    "\n",
    "for row in query_results:\n",
    "    # store the results in convention_data\n",
    "    text = row[0]  \n",
    "    party = row[1] \n",
    "\n",
    "    # Cleaning processing\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_text = ' '.join([word for word in tokens if word.isalpha() and word not in stop_words])\n",
    "\n",
    "    convention_data.append([cleaned_text, party])\n",
    "\n",
    "# for item in convention_data:\n",
    "#     print(\"Cleaned Text:\", item[0])\n",
    "#     print(\"Cleaned Party:\", item[1])\n",
    "#     print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elect taxes going raised cut', 'Republican'],\n",
       " ['state vermont strongly believing economic justice social justice racial justice environmental justice proudly supporting democracy constitution united states vehemently opposed authoritarianism racism trump administration proud cast votes vermont senator bernie sanders votes next president united states joe biden',\n",
       "  'Democratic'],\n",
       " ['singing', 'Democratic'],\n",
       " ['paying every worker fair wage', 'Democratic'],\n",
       " ['simply endure recession struggle survive working men women america get crushed yet time hand government washed career politician nothing puppet radical left democrats lifelong resident wisconsin fan badger football team many may realize wisconsin badgers president share three common qualities smart tough dependable businessman tell qualities need country leader need reelect donald trump thank god bless america',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2236 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n",
    "# print(\"Feature words:\", feature_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"    \n",
    "    ret_dict = dict()\n",
    "    words = text.split()\n",
    "\n",
    "    # if in feature words (fw), add it to the dictionary\n",
    "    for word in words:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"biden is the president\",feature_words)==\n",
    "       {'biden':True,'president':True})\n",
    "assert(conv_features(\"immigrant in america should be citizens\",feature_words)==\n",
    "                     {'immigrant':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assertions are successful for both parties. It indicates that the conv_features function is correctly identifying and returning the relevant feature words from conventions/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.1 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.8 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random guessing: 0.61\n"
     ]
    }
   ],
   "source": [
    "# calculate random guessing with most common party and count\n",
    "party_counts = Counter(party for text, party in convention_data)\n",
    "most_common_party, most_common_count = party_counts.most_common(1)[0]\n",
    "total_count = len(convention_data)\n",
    "\n",
    "# accuracy of random guessing\n",
    "random_guess_accuracy = most_common_count / total_count\n",
    "print(f\"Accuracy of random guessing: {random_guess_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_The Naive Bayes classifier's accuracy of 49.4% is notably lower than the random guessing accuracy of 61%, this indicates that the model is struggling to identify meaningful patterns, which is surprising given that Naive Bayes is typically a robust choice for text classification tasks. The disparity suggests that the chosen features may not adequately capture the complexities of the political speeches in the dataset._\n",
    "\n",
    "_Although, the analysis of informative features shows that certain words strongly correlate with specific parties, yet the model still fails to outperform random guessing. This discrepancy might point to issues in the data preprocessing stage, such as inadequate handling of stopwords or overly restrictive feature selection criteria. Some topics, such as \"climate\" and \"china,\" shows potential richness in the data that is not being utilized. It may also be beneficial to experiment with different classification algorithms, as alternatives like Support Vector Machines or Random Forests might yield better results. In summary, these findings highlight a critical need for further exploration of both feature engineering and model selection to enhance classification accuracy in political discourse analysis._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/users/rkartawi/Desktop/Ravita/MSADS/509/Mod4/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for row in results:\n",
    "    party = row[1]\n",
    "    tweet_text = row[2]\n",
    "\n",
    "    if isinstance(tweet_text, bytes):\n",
    "        tweet_text = tweet_text.decode('utf-8')\n",
    "    \n",
    "    # Cleaning process\n",
    "    tweet_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet_text, flags=re.MULTILINE)  # Remove URLs Regex\n",
    "    tokens = word_tokenize(tweet_text.lower()) \n",
    "    cleaned_text = ' '.join([word for word in tokens if word.isalpha() and word not in stop_words])  # Remove non-alphabetic and stop words\n",
    "\n",
    "    tweet_data.append([cleaned_text, party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(tweet_data, columns=['cleaned_text', 'party'])\n",
    "\n",
    "X = tweet_df['cleaned_text']\n",
    "y = tweet_df['party']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: met w angie settle wvhealthright charleston make healthcare accessible thousands west virginians every year\n",
      "Actual party is Republican and our classifier says Democratic. ✖\n",
      "\n",
      "Here's our (cleaned) tweet: absolute privilege recognize cpl rosser service country medal honor recipient\n",
      "Actual party is Republican and our classifier says Democratic. ✖\n",
      "\n",
      "Here's our (cleaned) tweet: time put america first deal iran put america harm way postnewstxcity\n",
      "Actual party is Republican and our classifier says Republican. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: fernando exactly kind young person america embracing alone across nation dreamers contributing amp strengthening communities america afford republicans continue push away\n",
      "Actual party is Democratic and our classifier says Democratic. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: vp middle class joe biden honor got ta love joe\n",
      "Actual party is Democratic and our classifier says Democratic. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: washingtonpost editorial reopen white house doors tourists\n",
      "Actual party is Republican and our classifier says Democratic. ✖\n",
      "\n",
      "Here's our (cleaned) tweet: americans stand solidarity afghan people following heinous attack carried ramadan\n",
      "Actual party is Democratic and our classifier says Democratic. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: unhinged overly emotional shrill amp needs smile believe kavanaughhearings\n",
      "Actual party is Democratic and our classifier says Democratic. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: capitalism trial week president obama went whirlwind tour wall street\n",
      "Actual party is Republican and our classifier says Republican. ✔\n",
      "\n",
      "Here's our (cleaned) tweet: keep pressure potus executive order must call muslim ban\n",
      "Actual party is Democratic and our classifier says Democratic. ✔\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "for tweet, party in tweet_data_sample:\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    X_sample = vectorizer.transform([tweet])  \n",
    "    estimated_party = classifier.predict(X_sample)[0]\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    match = '✔' if party == estimated_party else '✖'\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}. {match}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.79\n",
      "Classification Rpt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Democratic       0.77      0.89      0.82     74865\n",
      "  Republican       0.82      0.66      0.73     58067\n",
      "\n",
      "    accuracy                           0.79    132932\n",
      "   macro avg       0.79      0.77      0.78    132932\n",
      "weighted avg       0.79      0.79      0.78    132932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Naive Bayes accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['Democratic', 'Republican'])\n",
    "print(\"Classification Rpt:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    \n",
    "    # Transform the cleaned tweet to the vector\n",
    "    tweet_tfidf = vectorizer.transform([tweet])\n",
    "    \n",
    "    # Do the same thing as above and Store\n",
    "    estimated_party = classifier.predict(tweet_tfidf)[0] \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx >= num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of Actual vs Estimated Party for 10000 samples:\n",
      "\n",
      "Actual Party: Republican\n",
      "  Estimated Party: Republican - Count: 3013\n",
      "  Estimated Party: Democratic - Count: 1335\n",
      "\n",
      "Actual Party: Democratic\n",
      "  Estimated Party: Republican - Count: 536\n",
      "  Estimated Party: Democratic - Count: 5117\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCount of Actual vs Estimated Party for 10000 samples:\")\n",
    "for actual_party in parties:\n",
    "    print(f\"\\nActual Party: {actual_party}\")\n",
    "    for estimated_party in parties:\n",
    "        print(f\"  Estimated Party: {estimated_party} - Count: {results[actual_party][estimated_party]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_The Naive Bayes classifier achieved an overall accuracy of 79%, it means it correctly classified approximately four out of five tweets. The classification report highlights that the precision for predicting Democratic tweets is 77%, with a recall of 89%, suggesting the model is effective at identifying Democratic tweets but may occasionally misclassify Republican tweets as Democratic. In contrast, the precision for Republican tweets is higher at 82%, but the recall is lower at 66%, indicating that while the model is generally good at identifying Republican tweets, it misses a significant portion of them._\n",
    "\n",
    "_The confusion matrix only reveals 10,000 tweets, the model classification report has different result due to the different dataset. In this sample, 30.53% of Republican tweets correctly while misclassifying 13.68% as Democratic, and correctly identified 50.60% of Democratic tweets while misclassifying 5.20% as Republican. One improvements that can be made is particularly in increasing the recall for Republican tweets to reduce misclassification._ \n",
    "\n",
    "_In conclusion, although the speech data might not be sufficient in predicting the party, however having additional dataset (i.e: tweet), different feature engineering and algorithm, it could change the overall performance accuracy._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "\n",
    "    Dib, F. (n.d.). Build, test, and debug regex. regex101. https://regex101.com/\n",
    "\n",
    "    OpenAI. (2024). ChatGPT (September 24 version) [Large language model]. https://chat.openai.com/chat\n",
    "\n",
    "    Chandler, J. (n.d.). 37chandler/TM-NB-Conventions. GitHub. https://github.com/37chandler/tm-nb-conventions \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
